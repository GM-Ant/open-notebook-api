# Plan: Argparse-to-Schema Adapter Implementation

**Project Goal**: Implement a `ToolReflector` that can inspect an `argparse` setup (specifically from `OpenNotebookCLI`) and generate OpenAI-compatible JSON schemas for each command. This includes creating Pydantic models for the schema, writing comprehensive tests, and preparing for future integration.

**Key Deliverables**:
1.  `open_notebook/tool_reflector.py` with `ToolSpec` Pydantic model and `CLIInspector` class.
2.  `open_notebook/tool_registry.py` (skeleton).
3.  `tests/test_tool_reflection.py` with high test coverage.
4.  Updated FastAPI app to import the new reflector module.
5.  Example JSON schema outputs for `list-notebooks`, `add-url-source`, and `text-search`.

**Target Environment**: Python 3.10+ and Pydantic v2.

---

**Detailed Implementation Plan**

**Phase 1: Core Pydantic Models and File Setup**
*   **Task 1.1: Create Files**
    *   Create `open_notebook/tool_reflector.py`
    *   Create `open_notebook/tool_registry.py`
    *   Create `tests/test_tool_reflection.py`
*   **Task 1.2: Define Pydantic Models in `tool_reflector.py`**
    *   Import necessary modules: `argparse`, `typing (Any, Dict, List, Optional, Type)`, `pydantic (BaseModel, Field)`.
    *   `ToolParameterProperties(BaseModel)`: Represents the schema for a single parameter.
        *   `type: str` (e.g., "string", "integer", "boolean", "array")
        *   `description: Optional[str] = None`
        *   `enum: Optional[List[Any]] = None` (for arguments with `choices`)
        *   `default: Optional[Any] = None`
        *   `items: Optional[Dict[str, str]] = None` (e.g., `{"type": "string"}` for arrays of strings)
    *   `ToolParameters(BaseModel)`: Represents the "parameters" object in the OpenAI schema.
        *   `type: str = Field(default="object")`
        *   `properties: Dict[str, ToolParameterProperties]`
        *   `required: Optional[List[str]] = Field(default_factory=list)`
    *   `ToolSpec(BaseModel)`: Represents the overall OpenAI function-calling schema.
        *   `name: str` (the command name)
        *   `description: Optional[str] = None` (command's help text)
        *   `parameters: ToolParameters`

**Phase 2: `CLIInspector` Class Implementation (`tool_reflector.py`)**
*   **Task 2.1: `CLIInspector.__init__`**
    *   Import `OpenNotebookCLI` from `open_notebook_cli.py`.
    *   Instantiate `OpenNotebookCLI` to access its `parser`.
*   **Task 2.2: Helper `_get_subparser_action`** (singular, as there's typically one main `_SubParsersAction`)
    *   Method to find and return the `argparse._SubParsersAction` instance from the main parser. This action holds the choices for all subcommands.
*   **Task 2.3: `_infer_arg_type(action: argparse.Action) -> str`**
    *   Logic to map `argparse` action types/configurations to JSON schema types:
        *   `int` -> `"integer"`
        *   `float` -> `"number"`
        *   `action='store_true'`/`'store_false'` -> `"boolean"`
        *   `nargs` indicating multiple values (`*`, `+`, integer) -> `"array"`
        *   Default -> `"string"`
*   **Task 2.4: `_extract_parameter_definition(arg_action: argparse.Action) -> ToolParameterProperties`**
    *   Takes an `argparse.Action` (representing a single CLI argument) and returns a populated `ToolParameterProperties` model.
    *   Sets `type` using `_infer_arg_type`.
    *   Sets `description` from `arg_action.help`.
    *   Sets `enum` from `arg_action.choices`.
    *   Sets `default` from `arg_action.default` (if not `argparse.SUPPRESS`).
    *   If type is `"array"`, infers and sets `items` schema (e.g., `{"type": "string"}` based on `arg_action.type`).
*   **Task 2.5: `generate_schema_for_command(command_name: str) -> Optional[ToolSpec]`**
    *   Retrieves the specific subparser for the given `command_name`.
    *   Extracts the command's description.
    *   Iterates through the subparser's actions (`_actions`) to build:
        *   `properties`: A dictionary mapping argument destination names (`act.dest`) to their `ToolParameterProperties` (generated by `_extract_parameter_definition`).
        *   `required`: A list of argument destination names that are required.
            *   Positional arguments are required unless `nargs` is `?` or `*`.
            *   Optional arguments (flags) are required if `act.required is True`.
    *   Constructs and returns a `ToolSpec` model. Returns `None` if the command is not found.
*   **Task 2.6: `generate_all_schemas() -> Dict[str, ToolSpec]`**
    *   Iterates through all available command names (from `_get_subparser_action().choices`).
    *   Calls `generate_schema_for_command` for each.
    *   Returns a dictionary mapping command names to their `ToolSpec` objects.

**Phase 3: Skeleton for `tool_registry.py`**
*   **Task 3.1: Create Skeleton**
    *   In `open_notebook/tool_registry.py`, add a placeholder function like `load_tool_schemas()` and comments indicating its purpose for Phase 3 (e.g., it will use `CLIInspector` to get all schemas).

**Phase 4: Unit Testing (`tests/test_tool_reflection.py`)**
*   **Task 4.1: Setup and Fixtures**
    *   Import `pytest`, relevant models from `tool_reflector`, and `CLIInspector`.
    *   Create a `pytest.fixture` for an instance of `CLIInspector`.
*   **Task 4.2: Test `_infer_arg_type`**
    *   Cover all type inference cases: string, integer, float, boolean (store_true/false), array (from nargs). Use `mocker` to create `argparse.Action` mocks.
*   **Task 4.3: Test `_extract_parameter_definition`**
    *   Test extraction of `type`, `description`, `enum`, `default`, and `items` for arrays.
    *   Cover various `argparse.Action` configurations.
*   **Task 4.4: Test `generate_schema_for_command`**
    *   Test for the specified commands: `list-notebooks`, `add-url-source`, `text-search`.
    *   Assert the generated `ToolSpec` structure is correct (name, description, parameters.properties, parameters.required).
    *   Use `ToolSpec.model_validate(generated_schema.model_dump())` to ensure Pydantic validation passes.
*   **Task 4.5: Test `generate_all_schemas`**
    *   Verify it returns a dictionary with expected command keys and `ToolSpec` values.
*   **Task 4.6: Coverage Goal**
    *   Aim for >= 90% test coverage for `tool_reflector.py`.

**Phase 5: FastAPI Integration (Minimal)**
*   **Task 5.1: Update FastAPI App**
    *   In `api_main.py` (or the main FastAPI application file), add an import statement for `CLIInspector` from `open_notebook.tool_reflector`. This fulfills the requirement of importing the module, actual usage will be later.

**Phase 6: Documentation and Examples**
*   **Task 6.1: Generate Example Schemas**
    *   Use the implemented `CLIInspector` to generate and save the JSON schema outputs for `list-notebooks`, `add-url-source`, and `text-search`.

---

**Visual Plan (Mermaid Diagram):**

```mermaid
graph LR
    subgraph Input
        A[open_notebook_cli.py: OpenNotebookCLI & argparse setup]
    end

    subgraph ReflectionProcess [tool_reflector.py]
        B(CLIInspector) -- Instantiates & Uses --> A
        B -- Iterates Subcommands --> C{argparse.ArgumentParser for each command}
        C -- Contains --> D[argparse.Action for each argument]
        B -- Processes each --> D
        D -- _infer_arg_type --> E[Schema Type: string, int, bool, array]
        D -- _extract_parameter_definition --> F[ToolParameterProperties: type, desc, enum, default, items]
        F -- Aggregated into --> G[ToolParameters: properties, required]
        G -- Combined with Command Info --> H[ToolSpec Model]
    end

    subgraph Output
        H -- Serializes to --> I[OpenAI JSON Schema]
        J[Example Schemas for list-notebooks, add-url-source, text-search]
    end

    subgraph Testing [tests/test_tool_reflection.py]
        K(Pytest Tests) -- Validate --> B
        K -- Validate --> E
        K -- Validate --> F
        K -- Validate --> H
        K -- Ensures --> L[High Test Coverage]
    end

    subgraph Integration & Future
        M[tool_registry.py Skeleton]
        N[api_main.py imports tool_reflector]
    end

    A --> B
    H --> J